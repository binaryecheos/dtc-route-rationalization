{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c94ed71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from google.transit import gtfs_realtime_pb2\n",
    "import time\n",
    "import logging\n",
    "from typing import List, Dict, Optional\n",
    "import threading\n",
    "from dataclasses import dataclass\n",
    "import http.client\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efcd2fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class VehiclePosition:\n",
    "    timestamp: int\n",
    "    vehicle_id: str\n",
    "    trip_id: str\n",
    "    route_id: str\n",
    "    latitude: float\n",
    "    longitude: float\n",
    "    speed: Optional[float] = None\n",
    "    bearing: Optional[float] = None\n",
    "\n",
    "class RealtimeArchiver:\n",
    "    def __init__(self, api_key: str, archive_frequency: int = 30):\n",
    "        self.api_key = api_key\n",
    "        self.archive_frequency = archive_frequency\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "        self.is_running = False\n",
    "        self.archive_thread = None\n",
    "        self.archive_df = pd.DataFrame(columns=[\n",
    "            'timestamp', 'vehicle_id', 'trip_id', 'route_id',\n",
    "            'latitude', 'longitude', 'speed', 'bearing'\n",
    "        ])\n",
    "\n",
    "    def fetch_realtime_data(self, max_retries=3, backoff_factor=2) -> List[VehiclePosition]:\n",
    "        url = f\"https://otd.delhi.gov.in/api/realtime/VehiclePositions.pb\"\n",
    "        params = {'key': self.api_key}\n",
    "        attempt = 0\n",
    "        while attempt < max_retries:\n",
    "            try:\n",
    "                response = requests.get(url, params=params, timeout=20)\n",
    "                response.raise_for_status()\n",
    "                feed = gtfs_realtime_pb2.FeedMessage()\n",
    "                feed.ParseFromString(response.content)\n",
    "                positions = []\n",
    "                data = []\n",
    "                for entity in feed.entity:\n",
    "                    if entity.HasField('vehicle'):\n",
    "                        vehicle = entity.vehicle\n",
    "                        if vehicle.HasField('position'):\n",
    "                            pos_bearing = getattr(vehicle.position, 'bearing', None)\n",
    "                            pos_speed = getattr(vehicle.position, 'speed', None)\n",
    "                            vehicle_id = getattr(vehicle.vehicle, 'id', '') if vehicle.HasField('vehicle') else ''\n",
    "                            trip_id = getattr(vehicle.trip, 'trip_id', '') if vehicle.HasField('trip') else ''\n",
    "                            route_id = getattr(vehicle.trip, 'route_id', '') if vehicle.HasField('trip') else ''\n",
    "                            position = VehiclePosition(\n",
    "                                timestamp=feed.header.timestamp,\n",
    "                                vehicle_id=vehicle_id,\n",
    "                                trip_id=trip_id,\n",
    "                                route_id=route_id,\n",
    "                                latitude=vehicle.position.latitude,\n",
    "                                longitude=vehicle.position.longitude,\n",
    "                                speed=pos_speed,\n",
    "                                bearing=pos_bearing\n",
    "                            )\n",
    "                            positions.append(position)\n",
    "                            data.append({\n",
    "                                'timestamp': feed.header.timestamp,\n",
    "                                'vehicle_id': vehicle_id,\n",
    "                                'trip_id': trip_id,\n",
    "                                'route_id': route_id,\n",
    "                                'latitude': vehicle.position.latitude,\n",
    "                                'longitude': vehicle.position.longitude,\n",
    "                                'speed': pos_speed,\n",
    "                                'bearing': pos_bearing\n",
    "                            })\n",
    "                self._latest_df = pd.DataFrame(data)\n",
    "                self.logger.info(f\"Fetched {len(positions)} vehicle positions\")\n",
    "                return positions\n",
    "            except (requests.exceptions.RequestException, http.client.IncompleteRead) as e:\n",
    "                self.logger.error(f\"Network error fetching real-time data (attempt {attempt+1}): {e}\")\n",
    "                self._latest_df = pd.DataFrame()\n",
    "            except Exception as e:\n",
    "                self.logger.error(f\"Error parsing real-time data (attempt {attempt+1}): {e}\")\n",
    "                self._latest_df = pd.DataFrame()\n",
    "            attempt += 1\n",
    "            if attempt < max_retries:\n",
    "                time.sleep(backoff_factor ** attempt)\n",
    "        self.logger.error(\"All attempts to fetch real-time data failed.\")\n",
    "        self._latest_df = pd.DataFrame()\n",
    "        return []\n",
    "\n",
    "    def get_vehicle_positions_df(self) -> pd.DataFrame:\n",
    "        return self.archive_df.copy()\n",
    "\n",
    "    def save_positions(self, positions: List[VehiclePosition]) -> bool:\n",
    "        if not positions:\n",
    "            return True\n",
    "        try:\n",
    "            data = [{\n",
    "                'timestamp': pos.timestamp,\n",
    "                'vehicle_id': pos.vehicle_id,\n",
    "                'trip_id': pos.trip_id,\n",
    "                'route_id': pos.route_id,\n",
    "                'latitude': pos.latitude,\n",
    "                'longitude': pos.longitude,\n",
    "                'speed': pos.speed,\n",
    "                'bearing': pos.bearing\n",
    "            } for pos in positions]\n",
    "            new_df = pd.DataFrame(data)\n",
    "            self.archive_df = pd.concat([self.archive_df, new_df], ignore_index=True)\n",
    "            self.logger.info(f\"Appended {len(positions)} positions to DataFrame\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Failed to save positions: {e}\")\n",
    "            return False\n",
    "\n",
    "    def calculate_headways(self, route_id: str, stop_id: str, time_window: int = 3600) -> List[float]:\n",
    "        try:\n",
    "            end_time = int(time.time())\n",
    "            start_time = end_time - time_window\n",
    "            df = self.archive_df\n",
    "            mask = (\n",
    "                (df['route_id'] == route_id) &\n",
    "                (df['timestamp'] >= start_time) &\n",
    "                (df['timestamp'] <= end_time)\n",
    "            )\n",
    "            sub_df = df[mask]\n",
    "            if sub_df.empty:\n",
    "                return []\n",
    "            headways = []\n",
    "            vehicles = sub_df['vehicle_id'].unique()\n",
    "            for vehicle in vehicles:\n",
    "                vehicle_data = sub_df[sub_df['vehicle_id'] == vehicle].sort_values('timestamp')\n",
    "                if len(vehicle_data) > 1:\n",
    "                    diffs = vehicle_data['timestamp'].diff().dropna()\n",
    "                    headways.extend(diffs.tolist())\n",
    "            return headways\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Failed to calculate headways: {e}\")\n",
    "            return []\n",
    "\n",
    "    def get_route_performance(self, route_id: str, hours: int = 24) -> Dict:\n",
    "        try:\n",
    "            end_time = int(time.time())\n",
    "            start_time = end_time - (hours * 3600)\n",
    "            df = self.archive_df\n",
    "            mask = (\n",
    "                (df['route_id'] == route_id) &\n",
    "                (df['timestamp'] >= start_time) &\n",
    "                (df['timestamp'] <= end_time)\n",
    "            )\n",
    "            sub_df = df[mask]\n",
    "            if sub_df.empty:\n",
    "                return {}\n",
    "            return {\n",
    "                'position_count': len(sub_df),\n",
    "                'vehicle_count': sub_df['vehicle_id'].nunique(),\n",
    "                'first_record': int(sub_df['timestamp'].min()),\n",
    "                'last_record': int(sub_df['timestamp'].max())\n",
    "            }\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Failed to get route performance: {e}\")\n",
    "            return {}\n",
    "\n",
    "    def start_archiving(self):\n",
    "        if self.is_running:\n",
    "            self.logger.warning(\"Archiving already running\")\n",
    "            return\n",
    "        self.is_running = True\n",
    "        self.archive_thread = threading.Thread(target=self._archive_loop)\n",
    "        self.archive_thread.daemon = True\n",
    "        self.archive_thread.start()\n",
    "        self.logger.info(\"Archiving started\")\n",
    "\n",
    "    def stop_archiving(self):\n",
    "        self.is_running = False\n",
    "        if self.archive_thread:\n",
    "            self.archive_thread.join(timeout=5)\n",
    "        self.logger.info(\"Archiving stopped\")\n",
    "\n",
    "    def _archive_loop(self):\n",
    "        while self.is_running:\n",
    "            try:\n",
    "                positions = self.fetch_realtime_data()\n",
    "                if positions:\n",
    "                    self.save_positions(positions)\n",
    "                time.sleep(self.archive_frequency)\n",
    "            except Exception as e:\n",
    "                self.logger.error(f\"Error in archive loop: {e}\")\n",
    "                time.sleep(self.archive_frequency)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e9d3edc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1: Fetching real-time vehicle positions...\n",
      "Fetched 2034 vehicle positions.\n",
      "Positions appended to DataFrame.\n",
      "Waiting 120 seconds before next fetch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gourav Sahu\\AppData\\Local\\Temp\\ipykernel_26284\\2665286678.py:100: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  self.archive_df = pd.concat([self.archive_df, new_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2: Fetching real-time vehicle positions...\n",
      "Fetched 2033 vehicle positions.\n",
      "Positions appended to DataFrame.\n",
      "Waiting 120 seconds before next fetch...\n",
      "Iteration 3: Fetching real-time vehicle positions...\n",
      "Fetched 2045 vehicle positions.\n",
      "Positions appended to DataFrame.\n",
      "Waiting 120 seconds before next fetch...\n",
      "Iteration 4: Fetching real-time vehicle positions...\n",
      "Fetched 2044 vehicle positions.\n",
      "Positions appended to DataFrame.\n",
      "Waiting 120 seconds before next fetch...\n",
      "Iteration 5: Fetching real-time vehicle positions...\n",
      "Fetched 2051 vehicle positions.\n",
      "Positions appended to DataFrame.\n",
      "Waiting 120 seconds before next fetch...\n",
      "Iteration 6: Fetching real-time vehicle positions...\n",
      "Fetched 2055 vehicle positions.\n",
      "Positions appended to DataFrame.\n",
      "Waiting 120 seconds before next fetch...\n",
      "Iteration 7: Fetching real-time vehicle positions...\n",
      "Fetched 2053 vehicle positions.\n",
      "Positions appended to DataFrame.\n",
      "Waiting 120 seconds before next fetch...\n",
      "Iteration 8: Fetching real-time vehicle positions...\n",
      "Fetched 2071 vehicle positions.\n",
      "Positions appended to DataFrame.\n",
      "Waiting 120 seconds before next fetch...\n",
      "Iteration 9: Fetching real-time vehicle positions...\n",
      "Fetched 2071 vehicle positions.\n",
      "Positions appended to DataFrame.\n",
      "Waiting 120 seconds before next fetch...\n",
      "Iteration 10: Fetching real-time vehicle positions...\n",
      "Fetched 2084 vehicle positions.\n",
      "Positions appended to DataFrame.\n",
      "Completed all iterations.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    api_key = \"L5jVvGl6iLEdSqnZG42pEm5LD94t1PYF\"\n",
    "    archiver = RealtimeArchiver(api_key=api_key, archive_frequency=120)\n",
    "    n = 10\n",
    "    for i in range(n):\n",
    "        print(f\"Iteration {i+1}: Fetching real-time vehicle positions...\")\n",
    "        positions = archiver.fetch_realtime_data()\n",
    "        if positions:\n",
    "            print(f\"Fetched {len(positions)} vehicle positions.\")\n",
    "            archiver.save_positions(positions)\n",
    "            print(\"Positions appended to DataFrame.\")\n",
    "        else:\n",
    "            print(\"No vehicle positions fetched or an error occurred.\")\n",
    "        if i < n - 1:\n",
    "            print(f\"Waiting 120 seconds before next fetch...\")\n",
    "            time.sleep(120)\n",
    "    print(\"Completed all iterations.\")\n",
    "\n",
    "    archiver.archive_df.to_csv(\"vehicle_positions_archive.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8477956e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
